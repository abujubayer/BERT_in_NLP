{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2cff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: what is the color of the fox?\n",
      "A1: brown\n",
      "\n",
      "Q2: Where is the dog sleeping?\n",
      "A2: in the sun\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Define the context\n",
    "context = \"The quick brown fox jumps over the lazy dog. The dog is sleeping peacefully in the sun.\"\n",
    "\n",
    "# Tokenize the context\n",
    "tokens = tokenizer(context, return_tensors=\"pt\")\n",
    "\n",
    "# Instantiate the question-answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Generate question-answer pairs\n",
    "questions = [\"what is the color of the fox?\", \"Where is the dog sleeping?\"]\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    # Generate answer\n",
    "    answer = qa_pipeline(question=question, context=context)\n",
    "    answers.append(answer)\n",
    "\n",
    "# Print the generated question-answer pairs\n",
    "for i, answer in enumerate(answers):\n",
    "    print(f\"Q{i + 1}: {questions[i]}\")\n",
    "    print(f\"A{i + 1}: {answer['answer']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2a17d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What color was used to emphasize the 50th anniversary of the Super Bowl?\n",
      "A1: Jhum\n",
      "\n",
      "Q2: Where can we find the Marmans?\n",
      "A2: Hill Tracts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Define the context\n",
    "context = \"\"\"\n",
    "The ethnic people in Bangladesh hold a very important place in the culture of the country. The majority of these people live in the Chittagong Hill Tracts.\n",
    "The others live in the regions of Mymensingh, Rajshahi, and Sylhet.\n",
    "They live in forest areas, in the hills and in rural areas.They practise Jhum cultivation.\n",
    "They clear a piece of land in the forest, prepare it and sow seeds in it.\n",
    "They are mostly farmers. By religion they are Hindus, Christians or Buddhists.They speak their own mother tongues.Some of them are the Chakmas, the Marmans, the Tipperas, and the Moorangs, who live in the Hill Tracts.The Santals live in Rajshahi. The Khasias and the Monipuries live in Sylhet and the Hajangs and the Garos live in Mymensingh.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the context\n",
    "tokens = tokenizer(context, return_tensors=\"pt\")\n",
    "\n",
    "# Instantiate the question-answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Generate question-answer pairs\n",
    "questions = [\"What color was used to emphasize the 50th anniversary of the Super Bowl?\", \"Where can we find the Marmans?\"]\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    # Generate answer\n",
    "    answer = qa_pipeline(question=question, context=context)\n",
    "    answers.append(answer)\n",
    "\n",
    "# Print the generated question-answer pairs\n",
    "for i, answer in enumerate(answers):\n",
    "    print(f\"Q{i + 1}: {questions[i]}\")\n",
    "    print(f\"A{i + 1}: {answer['answer']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f2b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ae540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
